{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to add any functions, import statements, and variables.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def predict(file):\n",
    "    # Fill in this function. This function should return a list of length 52\n",
    "    #   which is filled with floating point numbers. For example, the current\n",
    "    #   implementation predicts all the instances in test.csv as 10.0.\n",
    "\n",
    "    # 10 years data\n",
    "    data = pd.read_csv('train.csv')\n",
    "    train_data = data.set_index(\"Date\")\n",
    "\n",
    "    # 10 years data for training\n",
    "    train_X = train_data.iloc[:, :6].as_matrix()\n",
    "    train_Y = train_data.iloc[:, 6:].as_matrix()\n",
    "\n",
    "    #model\n",
    "    timesteps = 6\n",
    "    data_dim = 1\n",
    "    output_dim = 1\n",
    "    learning_rate = 0.001\n",
    "    training_epoch = 1000\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, timesteps, data_dim])\n",
    "    Y = tf.placeholder(tf.float32, [None, output_dim])\n",
    "\n",
    "    cells = []\n",
    "    for num in range(3):\n",
    "        # num_units을 크게 주면 epoch이 400을 넘어가며 널뛰기하는 현상보임. 128이하가 적당한 것을 발견\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(num_units=256, state_is_tuple=True)\n",
    "        # cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob = 0.7)\n",
    "        cells.append(cell)\n",
    "\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "    Y_pred = tf.contrib.layers.fully_connected(outputs[:, -1], output_dim, activation_fn=None)\n",
    "    loss = tf.reduce_mean(tf.square(Y_pred - Y))\n",
    "\n",
    "    learning_rate = 0.005\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    sess = tf.Session()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    reshaped_train_X = train_X.reshape((*train_X.shape, 1))\n",
    "\n",
    "    for epoch in range(training_epoch):\n",
    "        _, l = sess.run([train, loss], feed_dict={X: reshaped_train_X, Y: train_Y})\n",
    "\n",
    "    # Test step\n",
    "    test_data = pd.read_csv(file)\n",
    "    test_data = test_data.set_index(\"Date\")\n",
    "    test_X = test_data.iloc[:, :6].as_matrix()\n",
    "    reshaped_test_X = test_X.reshape((*test_X.shape, 1))\n",
    "\n",
    "    test_predict = sess.run(Y_pred, feed_dict={X: reshaped_test_X})\n",
    "    result = [i[0] for i in test_predict]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def write_result(predictions):\n",
    "    # You don't need to modify this function.\n",
    "    with open('result.csv', 'w') as f:\n",
    "        f.write('Value\\n')\n",
    "        for l in predictions:\n",
    "            f.write('{}\\n'.format(l))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # You don't need to modify this function.\n",
    "    predictions = predict('test.csv')\n",
    "    write_result(predictions)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # You don't need to modify this part.\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
